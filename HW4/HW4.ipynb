{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSoklTpd64He"
   },
   "source": [
    "## Homework 4: due 2022/05/09 23:59 (100%)\n",
    "\n",
    "### - Tutorial : \n",
    "\n",
    "1. Training on MNIST: https://www.kaggle.com/code/juiyangchang/cnn-with-pytorch-0-995-accuracy\n",
    "2. Torchvision transforms: https://pytorch.org/vision/stable/transforms.html\n",
    "3. Pytorch learning rate scheduler: https://pytorch.org/docs/stable/optim.html\n",
    "4. How to get learning rate: https://stackoverflow.com/questions/52660985/pytorch-how-to-get-learning-rate-during-training\n",
    "\n",
    "### - After you go through the tutorials, you should be able to work on this assignment.\n",
    "\n",
    "### - Please answer the following questions and work directly on this jupyter notebook.\n",
    "\n",
    "### - Make sure the code can be run and show the result and figures properly.\n",
    "\n",
    "### - Please write down your observation with markdown in this notebook briefly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1Qow4p4JyoZ"
   },
   "source": [
    "#### You will train a multi-class classfication model in this part. The data contains the images with three categories: cats, dogs and pandas. You can find the details of each column at https://www.kaggle.com/datasets/ashishsaxena2209/animal-image-datasetdog-cat-and-panda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRxjcEhVJyoa"
   },
   "outputs": [],
   "source": [
    "# Import necessory modules\n",
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as tr\n",
    "import torchvision.models as models\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import PIL.Image as Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkUvji7JJyoc"
   },
   "outputs": [],
   "source": [
    "# For reproduce the result\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBfm-Dv_Jyoc"
   },
   "source": [
    "### 1. Define the model and dataset (30%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBCIhUisJyoc"
   },
   "source": [
    "#### 1.1 Please create a class **AnimalDataset** for loading the data, and a varibale ***transform*** for the preprocessing transformation should be created for later usage.  (15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLDimMKKhMlt"
   },
   "outputs": [],
   "source": [
    "class AnimalDataset():\n",
    "    def __init__():\n",
    "        \n",
    "        \n",
    "    def __len__():\n",
    "        \n",
    "    \n",
    "    def __getitem__():\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63fy4yM3Jyod"
   },
   "source": [
    "#### 1.2 Please create a class **CNN** as your network with the architecture below. (15%)\n",
    "##### (Note. Please determine the output layer by the task)\n",
    "\n",
    "| Block 1 | Block 2 |  Fully Connected Layer |\n",
    "|:---:|:---:|:---:|\n",
    "| 3x3 conv, 64 | 3x3 conv, 128 |  Linear, 512 |\n",
    "| ReLU         | ReLU   |Dropout(p=0.5)  |\n",
    "| 2x2 MaxPooling, downsampling factor 2       | 2x2 MaxPooling, downsampling factor 2   | ReLU  |\n",
    "|          |    |Linear, 256  |\n",
    "|          |    |Dropout(p=0.5)  |\n",
    "|          |    |ReLU |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLj2syELJyod"
   },
   "outputs": [],
   "source": [
    "class CNN():\n",
    "    def __init__():\n",
    "\n",
    "        \n",
    "    def forward(self, X):\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzzU8E9tJyod"
   },
   "source": [
    "### 2. Train the model (70%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-tpjTl4Jyoe"
   },
   "source": [
    "#### 2.1 Please load the train/validation/test data from ***./animals*** respectively and resize the image to 32x32. For the data preprocessing, please apply ***RandomHorizontalFlip(p=0.5)*** and ***RandomRotation((-10,10))*** as data augmentations. Also, scale all the value in the range between 0 and 1 and normalize with mean value ***(0.485,0.456,0.406)*** and standard deviation ***(0.229,0.224,0.225)*** for RGB channel respectively. At last, create the DataLoaders with batch size 32.(10%)\n",
    "##### (Note. The mean and standard deviation is calculated from ImageNet dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESJe2OPQhMlw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uc_6FYjUJyoh"
   },
   "source": [
    "#### 2.2 Train the CNN model with the same hyperpameters below and do the validation every epoch. Choose the appropriate type of loss according to the task. Please record the learning rate, training/validation loss and training/validation accuracy every epoch. Also, save the model weights as ***model_without_scheduler.pth***(20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI3037YbJyoh"
   },
   "source": [
    "\n",
    "| | Learning rate | epochs | optimizer | weight decay | $\\beta _1$|$\\beta _2$|\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|***Hyperparameter***| 5e-3 | 100 | Adam | 1e-2 | 0.9 | 0.99 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebwoSasxhMlx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avE8BETtJyoh"
   },
   "source": [
    "#### 2.3 Please draw the plot the learning rate, training/validation loss and training/validation accuracy and write down the observation. (10%)\n",
    "##### (Example figure)\n",
    "![image.png](https://github.com/tingyan08/Deep-Learning-and-Computer-Vision/blob/main/HW4/img/curve1.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oMQFpKvhMly"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYmcSPiohMly"
   },
   "source": [
    "#### 2.4 Please retrain model with learning rate decay with decreasing factor 0.1 at 20 epoch and 60 epoch. The other parameters are as same as last question. Also, redraw the learning rate, accuracy and loss curves and save the weights as ***model_with_scheduler.pth***. (10%)\n",
    "##### (Example figure)\n",
    "![image.png](https://github.com/tingyan08/Deep-Learning-and-Computer-Vision/blob/main/HW4/img/curve2.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uBa7GI6hMlz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXMwYL9jJyoi"
   },
   "source": [
    "#### 2.5 Please calculate the confusion matrix and print the accuracy of two models with the test dataset. (10%)\n",
    "##### (Example figure)\n",
    "![image.png](https://github.com/tingyan08/Deep-Learning-and-Computer-Vision/blob/main/HW4/img/confusion%20matrix.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wC3mvrkDhMlz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZAmBfLahMlz"
   },
   "source": [
    "#### 2.6 Please choose the best model to predict the categories of images in the ***./animals/predict*** folder and show the figure with the prediction as title of each axes. (10%)\n",
    "##### (Example figure)\n",
    "![image.png](https://github.com/tingyan08/Deep-Learning-and-Computer-Vision/blob/main/HW4/img/img1.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utXQZNQdhMlz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
